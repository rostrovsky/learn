{
  "title": "Artificial Intelligence Fundamentals & Generative AI",
  "version": 1,
  "cards": [
    {
      "id": 1,
      "front": "What is Artificial Intelligence (AI)?",
      "back": [
        "A computer system that imitates some aspect of human behavior or capabilities such as recognizing speech, classifying images, translating languages, making decisions, and predicting outcomes."
      ]
    },
    {
      "id": 2,
      "front": "How does Generative AI differ from regular AI?",
      "back": [
        "Regular AI: Primarily imitates specific human behaviors (e.g., speech recognition, image classification, translation).",
        "Generative AI: Focuses on creating original content after being trained on large amounts of information."
      ]
    },
    {
      "id": 3,
      "front": "What forms can original content created by Generative AI take?",
      "back": [
        "Natural language: conversations, instructions, summaries, text generation.",
        "Code: functions, debugging help, test cases.",
        "Images: pictures generated from text prompts."
      ]
    },
    {
      "id": 4,
      "front": "What is a Large Language Model (LLM)?",
      "back": [
        "A neural network with billions or trillions of parameters trained to predict the next token, enabling human-like text generation and many language tasks.",
        "Examples include GPT and Llama."
      ]
    },
    {
      "id": 5,
      "front": "What is a \"prompt\" in the context of LLMs?",
      "back": [
        "The natural-language instructions or input given to a Large Language Model; prompt quality strongly influences response quality."
      ]
    },
    {
      "id": 6,
      "front": "What is \"inference\" in the context of LLMs?",
      "back": [
        "The process where a trained LLM predicts the next token repeatedly until an end-of-sequence, producing its output for a given prompt."
      ]
    },
    {
      "id": 7,
      "front": "What kind of data are Large Language Models trained on?",
      "back": [
        "Huge datasets from the web, Wikipedia, books, and other corpora; specific datasets vary by model."
      ]
    },
    {
      "id": 8,
      "front": "What are \"parameters\" in an LLM, and why are they important?",
      "back": [
        "Parameters are the weights and biases in the neural network.",
        "More parameters generally enable better capabilities.",
        "Modern models have billions to trillions of parameters and are read-only after training."
      ]
    },
    {
      "id": 9,
      "front": "Are LLMs considered Artificial General Intelligence (AGI)?",
      "back": [
        "No. They are powerful for language tasks but do not learn like AGI and are focused on next-token prediction (often weak at complex math)."
      ]
    },
    {
      "id": 10,
      "front": "What is the Transformer model and its significance?",
      "back": [
        "The foundational architecture (from 'Attention Is All You Need') used by modern LLMs.",
        "Characterized by encoder-decoder design; many models like GPT use decoder-only variants to process and generate text."
      ]
    },
    {
      "id": 11,
      "front": "What are \"tokens\" and \"tokenization\" in LLMs?",
      "back": [
        "Tokens are small text units (words, subwords, punctuation, emojis).",
        "Tokenization splits text into tokens and maps them to numeric IDs."
      ]
    },
    {
      "id": 12,
      "front": "What is an \"embedding model\" and what does it do?",
      "back": [
        "It converts tokens into vectors that capture semantic meaning.",
        "Semantically similar words have vectors that are numerically close (e.g., 'boss' and 'manager')."
      ]
    },
    {
      "id": 13,
      "front": "Why is positional encoding necessary in LLMs?",
      "back": [
        "Word order affects meaning; positional encoding injects position information into word vectors (often via sine/cosine functions)."
      ]
    },
    {
      "id": 14,
      "front": "What is self-attention and why is it important?",
      "back": [
        "It lets the model weigh the importance of different words relative to each other, preserving context across long inputs and outputs."
      ]
    },
    {
      "id": 15,
      "front": "What is GPT and what are some characteristics?",
      "back": [
        "GPT is a Generative Pre-trained Transformer from OpenAI.",
        "Pre-trained on large datasets; newer versions have more parameters and larger context windows.",
        "The context window limits how much input and output the model can handle at once."
      ]
    },
    {
      "id": 16,
      "front": "How does ChatGPT relate to GPT?",
      "back": [
        "ChatGPT is GPT further trained for dialogue using supervised examples and preference tuning to behave well in conversations."
      ]
    },
    {
      "id": 17,
      "front": "What is the role of Microsoft Copilots?",
      "back": [
        "They orchestrate between users and LLMs: ground with data (e.g., Graph, Bing), build a meta-prompt, call the LLM, and present results.",
        "A SaaS-like end-to-end generative AI experience."
      ]
    },
    {
      "id": 18,
      "front": "What is prompt engineering and why is it critical?",
      "back": [
        "The practice of crafting effective prompts to elicit the best responses.",
        "Techniques include explicit instructions, role specification, zero-shot, few-shot, and grounding."
      ]
    },
    {
      "id": 19,
      "front": "What is \"grounding\" in prompt engineering?",
      "back": [
        "Adding specific external data to the prompt (e.g., recent emails) so the LLM has relevant context it wouldn’t otherwise know."
      ]
    },
    {
      "id": 20,
      "front": "What is the Azure OpenAI Service?",
      "back": [
        "An Azure service hosting OpenAI models (GPT, embeddings, image models) within Microsoft’s infrastructure, exposed via API and managed in Azure OpenAI Studio."
      ]
    },
    {
      "id": 21,
      "front": "What is Machine Learning (ML)?",
      "back": [
        "A subset of AI where systems learn from past data to build models that make future predictions without explicit step-by-step programming."
      ]
    },
    {
      "id": 22,
      "front": "What are \"features\" and \"labels\" in ML training data?",
      "back": [
        "Features: input characteristics (pixels, temperatures, square footage).",
        "Labels: the correct answers associated with features (e.g., class name, numeric value)."
      ]
    },
    {
      "id": 23,
      "front": "What is supervised learning in ML?",
      "back": [
        "Training with labeled data to map inputs to outputs.",
        "Includes regression (numeric predictions) and classification (discrete categories)."
      ]
    },
    {
      "id": 24,
      "front": "What is unsupervised learning in ML?",
      "back": [
        "Training without labels, discovering patterns such as clusters based on similarities."
      ]
    },
    {
      "id": 25,
      "front": "What is deep learning and how does it relate to ML?",
      "back": [
        "A subset of ML using neural networks with many hidden layers to model complex relationships; powers LLMs and other advanced AI."
      ]
    },
    {
      "id": 26,
      "front": "Describe the basic structure and function of a neural network.",
      "back": [
        "Layers: input, one or more hidden, and output layers connected by weighted edges.",
        "Neurons apply activation functions; weights and biases enable complex pattern modeling."
      ]
    },
    {
      "id": 27,
      "front": "What is Azure Machine Learning Studio used for?",
      "back": [
        "An Azure platform for custom ML: datasets, labeling, training, evaluation, and deployment (e.g., to containers)."
      ]
    },
    {
      "id": 28,
      "front": "What does \"multimodal AI\" mean?",
      "back": [
        "AI that understands and interacts with multiple data types (text, images, audio, video); e.g., GPT-4o is multimodal."
      ]
    },
    {
      "id": 29,
      "front": "What are the main types of Azure AI Services resources?",
      "back": [
        "Single Service Type: one capability (often with a free tier), own endpoint/key.",
        "Multi-Service Account: most AI services under one account (no free tier).",
        "Azure OpenAI Service and Azure AI Search are separate resource types."
      ]
    },
    {
      "id": 30,
      "front": "How do apps connect and authenticate to Azure AI Services?",
      "back": [
        "REST endpoints and SDKs for requests/responses in JSON.",
        "Authentication via keys (e.g., in Key Vault) or Entra ID with RBAC/Managed Identities."
      ]
    },
    {
      "id": 31,
      "front": "Why is Responsible AI crucial, and what risks does it address?",
      "back": [
        "AI shifts decisions from humans to systems, introducing risks: bias, errors, data exposure, lack of inclusiveness, transparency, and accountability."
      ]
    },
    {
      "id": 32,
      "front": "List the six key principles of Responsible AI.",
      "back": [
        "Fairness",
        "Reliability & Safety",
        "Privacy & Security",
        "Inclusiveness",
        "Transparency",
        "Accountability"
      ]
    },
    {
      "id": 33,
      "front": "What capabilities does Azure AI Image Analysis offer?",
      "back": [
        "Captions and tags; object detection with bounding boxes; background removal and smart crops; small-scale OCR via the 'read' feature."
      ]
    },
    {
      "id": 34,
      "front": "What are the main functions of Azure AI Face services?",
      "back": [
        "Face detection with pose/landmarks/mask, liveness checks, identification and verification; no emotion or gender; some features require onboarding."
      ]
    },
    {
      "id": 35,
      "front": "How do Custom Vision services enable custom image training?",
      "back": [
        "Older Custom Vision uses CNNs (~15 images/category).",
        "Newer Image Analysis v4.0 uses Transformer models; workable with 2–5 images, better with ~50–60; training takes longer."
      ]
    },
    {
      "id": 36,
      "front": "What are key features of the Azure AI Language service?",
      "back": [
        "Language detection, sentiment, key phrases, entity recognition; summarization; question answering from a knowledge base."
      ]
    },
    {
      "id": 37,
      "front": "What is the Azure Bot Service used for?",
      "back": [
        "Building, publishing, and managing chatbots that can use knowledge bases and deploy across channels like Teams, web, and email."
      ]
    },
    {
      "id": 38,
      "front": "What does the Azure AI Language Understanding (LUIS) service do?",
      "back": [
        "Extracts intents and entities from user utterances (e.g., intent: 'turn on'; entity: 'lights') for automation scenarios."
      ]
    },
    {
      "id": 39,
      "front": "What functionalities do Azure AI Speech services provide?",
      "back": [
        "Text-to-speech, speech-to-text, language recognition, and speech translation."
      ]
    },
    {
      "id": 40,
      "front": "What are the capabilities of the Azure AI Translator service?",
      "back": [
        "Translate text/documents; custom terms; profanity filters; selective translation to preserve specific words."
      ]
    },
    {
      "id": 41,
      "front": "What is Azure AI Document Intelligence and its uses?",
      "back": [
        "Large-scale document analysis with structured outputs, pre-built models (receipts, invoices, IDs), custom models with few examples, and JSON outputs."
      ]
    },
    {
      "id": 42,
      "front": "What is knowledge mining and how does Azure AI Search help?",
      "back": [
        "Extracts insights from large data; Azure AI Search uses skillsets and embeddings to build text and vector indexes, supports hybrid search and reranking; foundational for RAG."
      ]
    },
    {
      "id": 43,
      "front": "Define Machine Learning (ML).",
      "back": [
        "A subset of AI where systems learn patterns from data to make predictions without explicit programming."
      ]
    },
    {
      "id": 44,
      "front": "What is training data in ML?",
      "back": [
        "Labeled examples used to teach a model the mapping from inputs (features) to outputs (labels)."
      ]
    },
    {
      "id": 45,
      "front": "What are features in ML?",
      "back": [
        "Input variables describing each example used by the model to learn."
      ]
    },
    {
      "id": 46,
      "front": "What are labels in ML?",
      "back": [
        "The correct answers or target outputs associated with each training example."
      ]
    },
    {
      "id": 47,
      "front": "What is an ML algorithm?",
      "back": [
        "A procedure (e.g., decision trees, linear regression, SVM) that learns relationships between features and labels."
      ]
    },
    {
      "id": 48,
      "front": "What is an ML model?",
      "back": [
        "The trained artifact that can make predictions on new, unseen data."
      ]
    },
    {
      "id": 49,
      "front": "Why is ML training iterative?",
      "back": [
        "Models are refined via validation/testing and parameter tuning to improve performance."
      ]
    },
    {
      "id": 50,
      "front": "Supervised learning — definition",
      "back": [
        "Learning from labeled data to predict outputs for new inputs."
      ]
    },
    {
      "id": 51,
      "front": "Regression — definition & example",
      "back": [
        "Predicts a numeric value (e.g., house price from square footage)."
      ]
    },
    {
      "id": 52,
      "front": "Classification — definition",
      "back": [
        "Predicts a category or class label for an input."
      ]
    },
    {
      "id": 53,
      "front": "Binary vs. multiclass classification",
      "back": [
        "Binary: two outcomes (spam/not spam).",
        "Multiclass: more than two outcomes (e.g., movie genre)."
      ]
    },
    {
      "id": 54,
      "front": "Unsupervised learning — definition",
      "back": [
        "Finds patterns in unlabeled data (e.g., clustering similar items)."
      ]
    },
    {
      "id": 55,
      "front": "What is Deep Learning (DL)?",
      "back": [
        "A subset of ML using multi-layer neural networks to model complex relationships."
      ]
    },
    {
      "id": 56,
      "front": "Neural network basics",
      "back": [
        "Networks of neurons (units) connected by weighted edges that transform inputs through layers."
      ]
    },
    {
      "id": 57,
      "front": "Neurons and activation functions",
      "back": [
        "Units apply nonlinear functions to inputs; they 'activate' to pass signals forward."
      ]
    },
    {
      "id": 58,
      "front": "Layers in a neural network",
      "back": [
        "Input layer → hidden layers (processing) → output layer (predictions)."
      ]
    },
    {
      "id": 59,
      "front": "Weights, biases, and parameters",
      "back": [
        "Weights connect neurons; biases shift activations; all trainable parameters are optimized during training."
      ]
    },
    {
      "id": 60,
      "front": "Why do large models often perform better?",
      "back": [
        "More parameters (often billions) can capture richer patterns, improving accuracy (with enough data/compute)."
      ]
    },
    {
      "id": 61,
      "front": "What is a Transformer model?",
      "back": [
        "A neural architecture based on attention mechanisms; foundation for modern LLMs like GPT."
      ]
    },
    {
      "id": 62,
      "front": "Generative AI can create…",
      "back": [
        "Natural language (chat, summaries, answers), images (text-to-image), and code (authoring, debugging)."
      ]
    },
    {
      "id": 63,
      "front": "What is a Large Language Model (LLM)?",
      "back": [
        "A Transformer-based model trained on massive text corpora to predict the next token in a sequence."
      ]
    },
    {
      "id": 64,
      "front": "LLM inference — how it works",
      "back": [
        "Given a prompt, the model repeatedly predicts the next token until an end condition is reached."
      ]
    },
    {
      "id": 65,
      "front": "LLM training data & compute",
      "back": [
        "Trained on large datasets (web, books, Wikipedia) using substantial GPU compute to learn parameters."
      ]
    },
    {
      "id": 66,
      "front": "Are LLM parameters updated during inference?",
      "back": [
        "No. At inference time, the model acts read-only; parameters don’t change."
      ]
    },
    {
      "id": 67,
      "front": "Transformer components: encoder & decoder",
      "back": [
        "Encoder processes inputs; decoder generates outputs. GPTs are primarily decoder-only."
      ]
    },
    {
      "id": 68,
      "front": "Text → tokens",
      "back": [
        "Input text is tokenized into words/sub-words/punctuation for processing."
      ]
    },
    {
      "id": 69,
      "front": "Tokens → embeddings",
      "back": [
        "Tokens become vectors that capture semantic meaning; similar meanings have similar vectors."
      ]
    },
    {
      "id": 70,
      "front": "Positional encoding purpose",
      "back": [
        "Adds word-order information to embeddings so the model understands sequence order."
      ]
    },
    {
      "id": 71,
      "front": "Multi-head self-attention",
      "back": [
        "Mechanism to relate tokens across the sequence, capturing dependencies and context."
      ]
    },
    {
      "id": 72,
      "front": "Masked self-attention (decoder-only)",
      "back": [
        "Ensures each token can only attend to previous tokens, not future ones."
      ]
    },
    {
      "id": 73,
      "front": "Feed-forward networks in Transformers",
      "back": [
        "Per-token neural layers that transform attended representations into richer features."
      ]
    },
    {
      "id": 74,
      "front": "Context representation",
      "back": [
        "The resulting vectors summarizing what the model has understood so far to predict next tokens."
      ]
    },
    {
      "id": 75,
      "front": "Encoder-decoder vs. decoder-only",
      "back": [
        "Some models use both components; GPT uses decoder-only with inputs fed to the decoder."
      ]
    },
    {
      "id": 76,
      "front": "What is GPT?",
      "back": [
        "OpenAI’s Generative Pre-trained Transformer series for advanced language generation."
      ]
    },
    {
      "id": 77,
      "front": "GPT versions & context windows",
      "back": [
        "GPT-3.5, GPT-4, GPT-4 Turbo; newer versions often have more parameters and larger context windows."
      ]
    },
    {
      "id": 78,
      "front": "What is ChatGPT?",
      "back": [
        "A GPT variant fine-tuned for dialogue using supervised learning and reinforcement learning from human feedback (RLHF)."
      ]
    },
    {
      "id": 79,
      "front": "What is a context window?",
      "back": [
        "The maximum tokens (input + output) processed in one interaction; larger windows handle longer prompts."
      ]
    },
    {
      "id": 80,
      "front": "Prompt engineering — definition",
      "back": [
        "Crafting precise prompts to guide model behavior and output quality."
      ]
    },
    {
      "id": 81,
      "front": "Prompt engineering — key techniques",
      "back": [
        "Be explicit; use role-playing; zero-shot and few-shot examples; include constraints and desired formats."
      ]
    },
    {
      "id": 82,
      "front": "What is grounding (RAG)?",
      "back": [
        "Augment the prompt with relevant external data to improve factuality and reduce hallucinations."
      ]
    },
    {
      "id": 83,
      "front": "Microsoft & OpenAI partnership",
      "back": [
        "Microsoft provides supercomputing infrastructure and Azure hosting for OpenAI models."
      ]
    },
    {
      "id": 84,
      "front": "What is Azure OpenAI Service?",
      "back": [
        "Azure access to OpenAI models (GPT, embeddings, DALL·E) with enterprise controls."
      ]
    },
    {
      "id": 85,
      "front": "Azure OpenAI — deployment & access",
      "back": [
        "Deploy model instances in your subscription; use Studio for testing; integrate via REST APIs."
      ]
    },
    {
      "id": 86,
      "front": "Azure OpenAI — pricing model",
      "back": [
        "Usage-based by tokens for prompts and completions."
      ]
    },
    {
      "id": 87,
      "front": "What are Microsoft Copilots?",
      "back": [
        "GenAI assistants embedded in Microsoft products (Word, Teams, Windows, Dynamics, Bing, Security)."
      ]
    },
    {
      "id": 88,
      "front": "Copilots as orchestrators",
      "back": [
        "They ground prompts with app/APIs (e.g., Microsoft Graph, Bing), build a meta-prompt, then call the LLM."
      ]
    },
    {
      "id": 89,
      "front": "Copilots — hosting & compliance",
      "back": [
        "Microsoft runs model instances within Azure to meet regulatory requirements; delivered as SaaS."
      ]
    },
    {
      "id": 90,
      "front": "Azure Machine Learning Studio — purpose",
      "back": [
        "Build, train, deploy, and manage custom ML models in the cloud."
      ]
    },
    {
      "id": 91,
      "front": "Azure ML — key capabilities",
      "back": [
        "Datasets & labeling, algorithm training, containerized deployment (on-prem, AKS, ACI)."
      ]
    },
    {
      "id": 92,
      "front": "Azure AI Services — Vision: Image Analysis v4.0",
      "back": [
        "Captions, tags, object detection, background removal, smart cropping, OCR; supports custom vision with fewer images."
      ]
    },
    {
      "id": 93,
      "front": "Azure AI Services — Face API",
      "back": [
        "Face detection, liveness, identification/verification, pose, masks, glasses, landmarks (no emotion/gender)."
      ]
    },
    {
      "id": 94,
      "front": "Azure AI Services — Custom Vision (legacy)",
      "back": [
        "Older CNN-based custom classification/detection; typically needs more images."
      ]
    },
    {
      "id": 95,
      "front": "Azure AI Services — Language Service",
      "back": [
        "Language detection, sentiment, key phrases, NER, summarization."
      ]
    },
    {
      "id": 96,
      "front": "Azure AI — Q&A Maker / Question Answering",
      "back": [
        "Build knowledge bases from FAQs or custom pairs for bots and apps."
      ]
    },
    {
      "id": 97,
      "front": "Azure AI — LUIS",
      "back": [
        "Language Understanding service to extract intents and entities from user utterances."
      ]
    },
    {
      "id": 98,
      "front": "Azure AI — Speech capabilities",
      "back": [
        "Text-to-Speech, Speech-to-Text, and Speech Translation."
      ]
    },
    {
      "id": 99,
      "front": "Azure AI — Translation Service",
      "back": [
        "Translate text/documents between languages; supports custom glossaries."
      ]
    },
    {
      "id": 100,
      "front": "Document Intelligence (Forms Recognizer)",
      "back": [
        "Extract structured data from PDFs/images, forms, receipts, invoices using pre-built or custom models."
      ]
    },
    {
      "id": 101,
      "front": "Document Intelligence — semantic understanding",
      "back": [
        "Goes beyond OCR to interpret fields like addresses and invoices."
      ]
    },
    {
      "id": 102,
      "front": "Azure AI Search — purpose",
      "back": [
        "Knowledge mining: make private, heterogeneous data searchable with AI enrichment."
      ]
    },
    {
      "id": 103,
      "front": "Azure AI Search — pipelines",
      "back": [
        "Ingest from blobs/DBs/lakes; apply skill sets (chunking, OCR, NLP) during indexing."
      ]
    },
    {
      "id": 104,
      "front": "Embeddings & vector indexes",
      "back": [
        "Store semantic vectors for similarity search; enable semantic and hybrid retrieval."
      ]
    },
    {
      "id": 105,
      "front": "Hybrid search & semantic ranking",
      "back": [
        "Combine keyword and vector results, rerank by semantic relevance for better answers."
      ]
    },
    {
      "id": 106,
      "front": "RAG with Azure AI Search",
      "back": [
        "Use vector/keyword retrieval over private data to ground LLM answers."
      ]
    },
    {
      "id": 107,
      "front": "Azure AI resource types — single vs. multi-service",
      "back": [
        "Single: one capability, often free tier, granular costs.",
        "Multi: one resource for many services (excl. OpenAI/Search), simpler but less granular."
      ]
    },
    {
      "id": 108,
      "front": "Specialized resources",
      "back": [
        "Azure OpenAI Resource (OpenAI models) and Azure AI Search Resource (knowledge mining)."
      ]
    },
    {
      "id": 109,
      "front": "Endpoints & authentication",
      "back": [
        "Each service exposes REST endpoints; use API Keys or Entra ID (Azure AD) RBAC with managed identities/service principals."
      ]
    },
    {
      "id": 110,
      "front": "SDKs for Azure AI",
      "back": [
        "Language SDKs simplify calling REST APIs from applications."
      ]
    },
    {
      "id": 111,
      "front": "Responsible AI — why it matters",
      "back": [
        "Ensures trustworthy, ethical AI; mitigates risks; maximizes societal benefit."
      ]
    },
    {
      "id": 112,
      "front": "Responsible AI — common risks",
      "back": [
        "Bias, errors, data exposure, lack of inclusivity/trust, unclear accountability."
      ]
    },
    {
      "id": 113,
      "front": "Microsoft Responsible AI principle: Fairness",
      "back": [
        "Treat people equitably; detect and mitigate bias via testing and controls."
      ]
    },
    {
      "id": 114,
      "front": "Microsoft Responsible AI principle: Reliability & Safety",
      "back": [
        "Systems must perform consistently and safely; require rigorous testing and robust ops."
      ]
    },
    {
      "id": 115,
      "front": "Microsoft Responsible AI principle: Privacy & Security",
      "back": [
        "Protect personal/sensitive data; scrub sources; enforce data governance."
      ]
    },
    {
      "id": 116,
      "front": "Microsoft Responsible AI principle: Inclusiveness",
      "back": [
        "Empower all users regardless of background; design accessible, inclusive systems."
      ]
    },
    {
      "id": 117,
      "front": "Microsoft Responsible AI principle: Transparency",
      "back": [
        "Explain system purpose, limits, and operation to build user trust."
      ]
    },
    {
      "id": 118,
      "front": "Microsoft Responsible AI principle: Accountability",
      "back": [
        "People and organizations remain responsible for AI outcomes and compliance."
      ]
    },
    {
      "id": 119,
      "front": "Responsible GenAI — identify harms",
      "back": [
        "Use red teaming and stress tests to surface potential negative outcomes."
      ]
    },
    {
      "id": 120,
      "front": "Responsible GenAI — measure & mitigate",
      "back": [
        "Assess severity/frequency; apply content filters, prompt constraints, and guardrails."
      ]
    },
    {
      "id": 121,
      "front": "Responsible GenAI — operations",
      "back": [
        "Continuously monitor, log, and update systems to maintain safety and quality."
      ]
    },
    {
      "id": 122,
      "front": "What are content filters?",
      "back": [
        "Built-in mechanisms restricting harmful/inappropriate outputs; tunable under policy."
      ]
    },
    {
      "id": 123,
      "front": "What is model jailbreaking?",
      "back": [
        "Attempts to bypass safety policies; requires layered, robust defenses."
      ]
    },
    {
      "id": 124,
      "front": "Quiz concept: Regular AI vs. Generative AI",
      "back": [
        "Regular AI imitates/predicts; Generative AI creates new content."
      ]
    },
    {
      "id": 125,
      "front": "Quiz concept: Role of parameters in DL",
      "back": [
        "Trainable weights/biases learned to represent complex patterns and make accurate predictions."
      ]
    },
    {
      "id": 126,
      "front": "Quiz concept: Why Azure AI Search beyond keywords?",
      "back": [
        "It supports vector/semantic retrieval and hybrid search with semantic ranking for better relevance."
      ]
    },
    {
      "id": 127,
      "front": "Glossary: Activation function",
      "back": [
        "Transforms neuron inputs; introduces nonlinearity to enable complex decision boundaries."
      ]
    },
    {
      "id": 128,
      "front": "Glossary: Context window",
      "back": [
        "Max tokens (input+output) an LLM can handle in one turn."
      ]
    },
    {
      "id": 129,
      "front": "Glossary: Embeddings",
      "back": [
        "Vector representations capturing semantic meaning of tokens/documents."
      ]
    },
    {
      "id": 130,
      "front": "Glossary: Vector index",
      "back": [
        "Structure enabling efficient similarity search over embeddings."
      ]
    },
    {
      "id": 131,
      "front": "Glossary: Hybrid search",
      "back": [
        "Combines keyword and vector search for comprehensive retrieval."
      ]
    },
    {
      "id": 132,
      "front": "Glossary: Semantic ranking",
      "back": [
        "Reranks results based on meaning rather than keyword overlap alone."
      ]
    },
    {
      "id": 133,
      "front": "Glossary: Token & tokenizer",
      "back": [
        "Token: text unit (word/sub-word/punctuation). Tokenizer: splits text into tokens."
      ]
    },
    {
      "id": 134,
      "front": "Glossary: Softmax",
      "back": [
        "Converts logits to probabilities, often in output layers."
      ]
    },
    {
      "id": 135,
      "front": "Glossary: Zero-shot vs. few-shot",
      "back": [
        "Zero-shot: no examples in prompt. Few-shot: include a few exemplars to steer behavior."
      ]
    },
    {
      "id": 136,
      "front": "Glossary: RLHF (concept in ChatGPT)",
      "back": [
        "Reinforcement Learning from Human Feedback aligns model behavior with human preferences."
      ]
    },
    {
      "id": 137,
      "front": "Glossary: Managed identity (Azure)",
      "back": [
        "Azure-provided identity for services, eliminating stored credentials; used with RBAC."
      ]
    },
    {
      "id": 138,
      "front": "Glossary: Endpoint & API keys",
      "back": [
        "Endpoint: service URL. API key: secret for authenticating requests (or use Entra ID)."
      ]
    },
    {
      "id": 139,
      "front": "Glossary: Document Intelligence",
      "back": [
        "Azure service for extracting structured data from documents via pre-built or custom models."
      ]
    },
    {
      "id": 140,
      "front": "Glossary: LUIS",
      "back": [
        "Language Understanding service that extracts intents and entities from text."
      ]
    },
    {
      "id": 141,
      "front": "Give an early example of AI implementation.",
      "back": [
        "Early chess programs with explicitly coded logic."
      ]
    },
    {
      "id": 142,
      "front": "Name three classic ML algorithm families.",
      "back": [
        "Decision trees, linear/logistic regression, support vector machines."
      ]
    },
    {
      "id": 143,
      "front": "What is the typical ML workflow?",
      "back": [
        "Train on training data, evaluate on test/validation data, tune parameters, and deploy when performance is acceptable."
      ]
    },
    {
      "id": 144,
      "front": "What is Azure Machine Learning Studio used for?",
      "back": [
        "Building, training, evaluating, and deploying custom ML models, including data labeling and containerized deployment."
      ]
    },
    {
      "id": 145,
      "front": "What are neural network layers?",
      "back": [
        "Input layer, multiple hidden layers, and an output layer of interconnected neurons."
      ]
    },
    {
      "id": 146,
      "front": "What are weights and biases?",
      "back": [
        "Weights scale inputs along connections; biases shift neuron activation thresholds; both are learned during training."
      ]
    },
    {
      "id": 147,
      "front": "Name common activation functions.",
      "back": [
        "ReLU, sigmoid (among others)."
      ]
    },
    {
      "id": 148,
      "front": "Why is DL computationally intensive?",
      "back": [
        "Training deep networks requires large datasets and heavy compute (often GPUs) over long durations."
      ]
    },
    {
      "id": 149,
      "front": "What is softmax used for?",
      "back": [
        "To convert raw scores into a probability distribution over classes in the output layer."
      ]
    },
    {
      "id": 150,
      "front": "Define Generative AI.",
      "back": [
        "AI focused on creating original content (text, code, images) from learned patterns, not only imitating behavior."
      ]
    },
    {
      "id": 151,
      "front": "What parts of the Transformer does GPT use?",
      "back": [
        "Decoder-only architectures for next-token prediction."
      ]
    },
    {
      "id": 152,
      "front": "Zero-shot vs. few-shot prompting?",
      "back": [
        "Zero-shot: no examples provided.",
        "Few-shot: a few examples included in the prompt."
      ]
    },
    {
      "id": 153,
      "front": "How does scaling affect LLMs?",
      "back": [
        "More parameters and training data typically increase capability and generalization."
      ]
    },
    {
      "id": 154,
      "front": "What are Small Language Models (SLMs)?",
      "back": [
        "Smaller, specialized models optimized for cost and latency on targeted tasks."
      ]
    },
    {
      "id": 155,
      "front": "How do GPT versions differ?",
      "back": [
        "By capability and context window size (e.g., GPT-3.5, GPT-4, GPT-4 Turbo)."
      ]
    },
    {
      "id": 156,
      "front": "How is Microsoft related to OpenAI?",
      "back": [
        "Microsoft partners with OpenAI, providing supercomputing infrastructure and hosting models via Azure."
      ]
    },
    {
      "id": 157,
      "front": "What is Azure OpenAI Studio for?",
      "back": [
        "Managing deployments, experimenting in a Playground, and integrating models via APIs."
      ]
    },
    {
      "id": 158,
      "front": "Name typical Copilot capabilities.",
      "back": [
        "Summarization, content comparison/generation, code generation, and image generation (via DALL·E)."
      ]
    },
    {
      "id": 159,
      "front": "What service model do Copilots usually use?",
      "back": [
        "SaaS (Software as a Service)."
      ]
    },
    {
      "id": 160,
      "front": "What is Custom Vision (legacy)?",
      "back": [
        "Older CNN-based custom image service that typically requires more training data."
      ]
    },
    {
      "id": 161,
      "front": "What is Azure Question Answering (Q&A)?",
      "back": [
        "A service to build knowledge bases of Q&A pairs for use by bots and apps."
      ]
    },
    {
      "id": 162,
      "front": "What is Azure Bot Service?",
      "back": [
        "A framework to build, publish, and manage bots across channels (Teams, web chat, email)."
      ]
    },
    {
      "id": 163,
      "front": "What does Azure Translator do?",
      "back": [
        "Text/document translation with custom domains, profanity filtering, and selective translation."
      ]
    },
    {
      "id": 164,
      "front": "Give two examples of supervised learning outputs.",
      "back": [
        "Numeric regression (price), categorical classification (spam/not spam)."
      ]
    },
    {
      "id": 165,
      "front": "Name two benefits of Transformer architectures over older RNN/CNN for NLP.",
      "back": [
        "Parallelizable training via attention and better long-range dependency modeling."
      ]
    },
    {
      "id": 166,
      "front": "How do LLMs like GPT generate text at a high level?",
      "back": [
        "Tokenize input → embed tokens → add positional information → apply self-attention layers → predict the next token repeatedly until done."
      ]
    },
    {
      "id": 167,
      "front": "Do GPT-style LLMs use the full Transformer architecture?",
      "back": [
        "Modern GPT models are typically decoder-only Transformers focused on next-token prediction."
      ]
    },
    {
      "id": 168,
      "front": "Why is Responsible AI crucial for Generative AI?",
      "back": [
        "GenAI can create new content, introducing risks like bias, harm, or misinformation; governance and safeguards are essential."
      ]
    },
    {
      "id": 169,
      "front": "What is the role of Azure Machine Learning Studio?",
      "back": [
        "A platform to create datasets, label data, train/evaluate models, and deploy them to production."
      ]
    },
    {
      "id": 170,
      "front": "What is the Semantic Kernel and why use it?",
      "back": [
        "An orchestration framework that connects tools and data sources (e.g., Azure AI Search) to build grounded meta-prompts before invoking LLMs for more accurate, context-aware outputs."
      ]
    },
    {
      "id": 171,
      "front": "Give examples of AI capabilities.",
      "back": [
        "Recognizing speech and images.",
        "Translating languages.",
        "Making predictions from historical data.",
        "Assisting decisions."
      ]
    },
    {
      "id": 172,
      "front": "What is training data in ML?",
      "back": [
        "Labeled datasets with features (inputs) and labels (correct outputs)."
      ]
    },
    {
      "id": 173,
      "front": "Name some common ML algorithms.",
      "back": [
        "Linear regression, decision trees, support vector machines and more."
      ]
    },
    {
      "id": 174,
      "front": "What is an ML model?",
      "back": [
        "The artifact produced by training that maps inputs to predicted outputs for new data."
      ]
    },
    {
      "id": 175,
      "front": "How are ML models improved?",
      "back": [
        "Iteratively test on held-out data and tune parameters until accuracy targets are met."
      ]
    },
    {
      "id": 176,
      "front": "What are the main types of ML?",
      "back": [
        "Supervised learning and unsupervised learning."
      ]
    },
    {
      "id": 177,
      "front": "Name the basic layers of a neural network.",
      "back": [
        "Input layer, hidden layers, output layer."
      ]
    },
    {
      "id": 178,
      "front": "What are activation functions?",
      "back": [
        "Neuron rules that decide whether to pass a value onward based on inputs."
      ]
    },
    {
      "id": 179,
      "front": "How resource-intensive is deep learning training?",
      "back": [
        "Large models can require months of training and tens of thousands of powerful GPUs."
      ]
    },
    {
      "id": 180,
      "front": "What can Generative AI produce?",
      "back": [
        "Natural language (conversations, summaries, code), images and other media."
      ]
    },
    {
      "id": 181,
      "front": "List key prompt engineering techniques.",
      "back": [
        "Be explicit, use role prompting, zero-shot, few-shot examples."
      ]
    },
    {
      "id": 182,
      "front": "What is OpenAI known for?",
      "back": [
        "Developing GPT models and major advances in generative AI."
      ]
    },
    {
      "id": 183,
      "front": "How do GPT model versions differ?",
      "back": [
        "By parameter count and context window (e.g., GPT-4 Turbo supports ~128K input tokens, ~4K output tokens)."
      ]
    },
    {
      "id": 184,
      "front": "What is Microsoft’s role in generative AI?",
      "back": [
        "Partner providing large-scale data center infrastructure and GPU supercomputers for training."
      ]
    },
    {
      "id": 185,
      "front": "What is Azure OpenAI Studio?",
      "back": [
        "A UI to experiment, deploy models and expose them via API."
      ]
    },
    {
      "id": 186,
      "front": "How do apps connect LLMs to proprietary data on Azure?",
      "back": [
        "Use Azure AI Search and orchestration (e.g., Semantic Kernel) with vector embeddings for semantic retrieval."
      ]
    },
    {
      "id": 187,
      "front": "How are custom vision models trained on Azure today?",
      "back": [
        "With relatively few images using Transformer-based architectures, often outperforming older CNNs."
      ]
    },
    {
      "id": 188,
      "front": "What does Azure Face service detect?",
      "back": [
        "Faces, liveness, identity verification, head pose, masks, glasses and facial landmarks.",
        "No emotion or gender detection supported."
      ]
    },
    {
      "id": 189,
      "front": "How does Azure Question Answering work?",
      "back": [
        "Builds a knowledge base of Q&A pairs often used by bots (e.g., via Azure Bot Service)."
      ]
    },
    {
      "id": 190,
      "front": "Does Document Intelligence support prebuilt and custom models?",
      "back": [
        "Yes. Prebuilt models for common docs and no-code custom models trained with as few as five samples."
      ]
    },
    {
      "id": 191,
      "front": "Name common enrichment steps in AI Search skillsets.",
      "back": [
        "Chunking large docs, generating embeddings, calling other services (e.g., Vision for OCR)."
      ]
    },
    {
      "id": 192,
      "front": "What is the practical application of Responsible AI on Azure?",
      "back": [
        "Built-in content filters and protections; some severities adjustable; certain features require special permissions."
      ]
    }
  ]
}